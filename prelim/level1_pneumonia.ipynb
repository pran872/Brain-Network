{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaFlexNet(nn.Module):\n",
    "    def __init__(self, image_dimensions=(150, 150)):\n",
    "        print(\"Using Network with Single Layer Flex\")\n",
    "        super(PneumoniaFlexNet, self).__init__()\n",
    "\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.in_dimensions = (1, self.image_dimensions[0], self.image_dimensions[1])\n",
    "\n",
    "        dimension_tracer = DimensionTracer(self.in_dimensions)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.pool = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.conv1 = Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv4 = Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv5 = Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.flatten_size = 256 * 6 * 6\n",
    "        # self.flatten_size = 256 * 150 * 150\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = nn.ReLU()(self.conv2(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = nn.ReLU()(self.conv3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = nn.ReLU()(self.conv4(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = nn.ReLU()(self.conv5(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.pool(x)\n",
    "        # print('before', x.size())\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        # print('after', x.size())\n",
    "        # exit()\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
